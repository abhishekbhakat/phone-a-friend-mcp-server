import os
from typing import Any

import aiofiles

from phone_a_friend_mcp_server.tools.base_tools import BaseTool


class FaxAFriendTool(BaseTool):
    """
    Fax-a-Friend: Generate a master prompt file for manual AI consultation.

    ‚ö†Ô∏è  ONLY USE WHEN EXPLICITLY REQUESTED BY USER ‚ö†Ô∏è

    This tool creates a comprehensive master prompt and saves it to a file for manual
    copy-paste into external AI interfaces. It uses the same prompt structure as the
    phone_a_friend tool but requires manual intervention to get the AI response.

    Use this tool when:
    - The automated phone_a_friend tool is unavailable
    - You want to manually control which AI service to use
    - You need to consult multiple AI services with the same prompt
    - API access is limited or unavailable

    The tool generates a file that you can manually copy and paste into any AI interface.
    """

    @property
    def name(self) -> str:
        return "fax_a_friend"

    @property
    def description(self) -> str:
        return """üö® ONLY USE WHEN EXPLICITLY REQUESTED: This tool should ONLY be used when the user specifically asks you to "fax a friend" or requests manual AI consultation.
Do NOT use this tool automatically or suggest using it unless the user explicitly requests it.

Fax-a-Friend: Generate a master prompt file for manual AI consultation.

This tool creates a comprehensive master prompt and saves it to 'fax_a_friend.md' for manual
copy-paste into external AI interfaces. It uses the same prompt structure as the
phone_a_friend tool but requires manual intervention to get the AI response.

Use this tool when:
- The automated phone_a_friend tool is unavailable
- You want to manually control which AI service to use
- You need to consult multiple AI services with the same prompt
- API access is limited or unavailable

After running this tool, you'll need to manually copy the generated prompt and paste it
into your preferred AI interface."""

    @property
    def parameters(self) -> dict[str, Any]:
        return {
            "type": "object",
            "properties": {
                "all_related_context": {
                    "type": "string",
                    "description": (
                        "MANDATORY. Everything the friend AI needs to see:\n"
                        "- The full <file_tree> block (ASCII tree).\n"
                        '- One or more <file="‚Ä¶"> blocks with the current code.\n'
                        "- Known constraints (Python version, allowed deps, runtime limits, etc.).\n"
                        "- Any failing test output or traceback.\n"
                        "If it's not here, the friend AI can't use it."
                    ),
                },
                "any_additional_context": {
                    "type": "string",
                    "description": (
                        "Optional extras that help but aren't core code:\n"
                        "- Style guides, architecture docs, API specs.\n"
                        "- Performance targets, security rules, deployment notes.\n"
                        "- Similar past solutions or reference snippets.\n"
                        "Skip it if there's nothing useful."
                    ),
                },
                "task": {
                    "type": "string",
                    "description": (
                        "Plain-English ask. Be surgical.\n"
                        "Good examples:\n"
                        "- Refactor synchronous Flask app to async Quart. Keep py3.10.\n"
                        "- Identify and fix memory leak in src/cache.py.\n"
                        "- Add unit tests for edge cases in utils/math.py.\n"
                        'Bad: vague stuff like "make code better".'
                    ),
                },
            },
            "required": ["all_related_context", "task"],
        }

    async def run(self, **kwargs) -> dict[str, Any]:
        all_related_context = kwargs.get("all_related_context", "")
        any_additional_context = kwargs.get("any_additional_context", "")
        task = kwargs.get("task", "")

        # Create master prompt using the same logic as phone_a_friend
        master_prompt = self._create_master_prompt(all_related_context, any_additional_context, task)

        try:
            # Write to fax_a_friend.md in current working directory
            file_path = "fax_a_friend.md"

            async with aiofiles.open(file_path, "w", encoding="utf-8") as f:
                await f.write(master_prompt)

            # Get absolute path for user reference
            abs_path = os.path.abspath(file_path)

            return {
                "status": "success",
                "file_path": abs_path,
                "file_name": "fax_a_friend.md",
                "prompt_length": len(master_prompt),
                "context_length": len(all_related_context + any_additional_context),
                "task": task,
                "instructions": self._get_manual_workflow_instructions(abs_path),
            }

        except Exception as e:
            return {"status": "failed", "error": str(e), "file_path": "fax_a_friend.md", "context_length": len(all_related_context + any_additional_context), "task": task}

    def _create_master_prompt(self, all_related_context: str, any_additional_context: str, task: str) -> str:
        """Create a comprehensive prompt identical to PhoneAFriendTool's version."""

        prompt_parts = [
            "You are a highly capable AI assistant being consulted for critical thinking, complex reasoning and pair-programming caliber coding help.",
            "You have no memory of previous conversations, so all necessary context is provided below.",
            "",
            "=== TASK ===",
            task,
            "",
            "=== ALL RELATED CONTEXT ===",
            all_related_context,
        ]

        if any_additional_context.strip():
            prompt_parts.extend(
                [
                    "",
                    "=== ADDITIONAL CONTEXT ===",
                    any_additional_context,
                ]
            )

        prompt_parts.extend(
            [
                "",
                "=== INSTRUCTIONS ===",
                "- Analyze the code and requirements step-by-step.",
                "- Show your reasoning and propose concrete changes.",
                '- Provide updated code using the XML format (<file_tree> plus <file="‚Ä¶"> blocks).',
                "- Be explicit and practical.",
                "",
                "Please provide your analysis and updated code:",
            ]
        )

        return "\n".join(prompt_parts)

    def _get_manual_workflow_instructions(self, file_path: str) -> str:
        """Generate clear instructions for the manual workflow."""
        return f"""
üö® MANUAL INTERVENTION REQUIRED üö®

Your master prompt has been saved to: {file_path}

NEXT STEPS - Please follow these instructions:

1. üìÇ Open the file: {file_path}
2. üìã Copy the ENTIRE prompt content from the file
3. ü§ñ Paste it into your preferred AI chat interface (ChatGPT, Claude, Gemini, etc.)
4. ‚è≥ Wait for the AI's response
5. üìù Copy the AI's complete response
6. üîÑ Return to this conversation and provide the AI's response

The prompt is ready for any external AI service. Simply copy and paste the entire content.

üí° TIP: You can use the same prompt with multiple AI services to compare responses!
"""
